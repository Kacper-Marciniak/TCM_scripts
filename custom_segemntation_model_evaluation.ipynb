{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KacperMarciniak\\anaconda3\\envs\\env_main\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from PARAMETERS import *\n",
    "\n",
    "import json\n",
    "import statistics\n",
    "import glob\n",
    "import os\n",
    "import cv2 as cv\n",
    "\n",
    "# for evaluation without training\n",
    "from PARAMETERS import *\n",
    "from tkinter_dialog_custom import askdirectory\n",
    "\n",
    "while True:\n",
    "    CURRENT_DATASET = askdirectory(title=\"Select dataset folder\", initialdir=PATH_TRAINING_DATA_SEGMENTATION)\n",
    "    if os.path.exists(CURRENT_DATASET): break\n",
    "\n",
    "USE_OLD_EVAL = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "network_config = r\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(network_config))\n",
    "cfg.OUTPUT_DIR =  askdirectory(initialdir=PATH_MODELS_SEGMENTATION,title=\"Select trained model\")\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"TCM_test\", )\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
    "cfg.OUTPUT_DIR =  PATH_TRAINING_OUTPUT_DIR_SEGMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval_old(segmentation_predictor,path_current_dataset):\n",
    "    pth = os.path.join(path_current_dataset, r'test').replace('\\\\\\\\','\\\\').replace('\\\\','/')\n",
    "    failures_dictionary = DICTIONARY_FAILURES\n",
    "    \n",
    "    F1_score_global = []\n",
    "    \n",
    "    F1_score_global_stepienie, F1_score_global_narost, F1_score_global_zatarcie, F1_score_global_wykruszenie = [],[],[],[]\n",
    "\n",
    "    for label in glob.glob(f'{pth}/*json'): # iterate through eval dataset\n",
    "        base_name = (label.replace('\\\\\\\\','\\\\').replace('\\\\','/').split('/')[-1]).split('.')[0]\n",
    "        file = open(label, 'r')\n",
    "        json_label = json.load(file )\n",
    "        im = cv.imread(os.path.join(pth,f\"{base_name}.png\"))\n",
    "        print(os.path.join(pth,f\"{base_name}.png\"))\n",
    "        \n",
    "        label_outputs = {\n",
    "            \"wykruszenie\": np.zeros_like(im),\n",
    "            \"narost\": np.zeros_like(im),\n",
    "            \"stepienie\": np.zeros_like(im),\n",
    "            \"zatarcie\": np.zeros_like(im)\n",
    "        }\n",
    "\n",
    "        # Iterate over labels from .json file, merge it into 4 categories, draw it as bitmaps\n",
    "        for shape in json_label[\"shapes\"]:\n",
    "            point_list = np.array(shape['points'])\n",
    "            if len(point_list) > 2:\n",
    "                pts = point_list.reshape((-1, 1, 2))  \n",
    "                for class_name in failures_dictionary.values(): # Iterate over all instances classes\n",
    "                    if(shape[\"label\"]==class_name):\n",
    "                        label_outputs[class_name] = cv.fillPoly(label_outputs[class_name], np.int32([pts]), (255,255,255))\n",
    "                        \n",
    "        # Segmentation model inference\n",
    "        predictions = segmentation_predictor(im) # Make prediction \n",
    "        pred_masks = predictions[\"instances\"].to(\"cpu\").pred_masks.numpy()\n",
    "        pred_classes = predictions[\"instances\"].to(\"cpu\").pred_classes.numpy()\n",
    "        num_instances = pred_masks.shape[0] \n",
    "        pred_masks = np.moveaxis(pred_masks, 0, -1)\n",
    "        pred_masks_instance = []\n",
    "        \n",
    "        # Contains merged bitmaps for particular failures classes\n",
    "        inference_outputs = {\n",
    "            \"wykruszenie\": np.zeros_like(im),\n",
    "            \"narost\": np.zeros_like(im),\n",
    "            \"stepienie\": np.zeros_like(im),\n",
    "            \"zatarcie\": np.zeros_like(im)\n",
    "        }\n",
    "        # Contains temporary data used during merging\n",
    "        pred_masks_instance = {   \n",
    "            \"wykruszenie\": [],\n",
    "            \"narost\": [],\n",
    "            \"stepienie\": [],\n",
    "            \"zatarcie\": []\n",
    "        }\n",
    "\n",
    "        # Iterate over predicted defects, search for duplicated instances of the same class and merge them into single bitmap.\n",
    "        for i in range(num_instances): \n",
    "            for class_id in failures_dictionary: # Iterate over all instances classes\n",
    "                if(pred_classes[i] == class_id): \n",
    "                    failure_class = failures_dictionary[class_id] # Get name of the current class\n",
    "                    pred_masks_instance[failure_class].append(pred_masks[:, :, i:(i+1)]) \n",
    "                    inference_outputs[failure_class] = np.where(pred_masks_instance[failure_class][-1] == True, 255, inference_outputs[failure_class])\n",
    "    \n",
    "        F1_score_stepienie_m, F1_score_wykruszenie_m, F1_score_zatarcie_m, F1_score_narost_m = 0,0,0,0\n",
    "\n",
    "        for class_name in failures_dictionary.values():\n",
    "        \n",
    "            pred = cv.cvtColor(inference_outputs[class_name], cv.COLOR_BGR2GRAY)\n",
    "            label = cv.cvtColor(label_outputs[class_name], cv.COLOR_BGR2GRAY)\n",
    "            bitwiseOr = cv.bitwise_or(pred, label)\n",
    "            bitwiseAnd = cv.bitwise_and(pred, label) \n",
    "            #bitwiseXor = cv.bitwise_xor(pred, label)\n",
    "            TP = bitwiseAnd  # TP - a sample is predicted to be positive and its label is actually positive\n",
    "            TN = cv.bitwise_not(bitwiseOr) # TN - a sample is predicted to be negative and its label is actually negative\n",
    "            FP = cv.bitwise_xor(TP,pred) # FP - a sample is predicted to be positive and its label is actually negative\n",
    "            FN = cv.bitwise_and(cv.bitwise_not(pred),cv.bitwise_xor(label,TP)) # FN - a sample is predicted to be negative and its label is actually positive\n",
    "\n",
    "            TP = cv.countNonZero(TP)\n",
    "            TN = cv.countNonZero(TN)\n",
    "            FP = cv.countNonZero(FP)\n",
    "            FN = cv.countNonZero(FN)\n",
    "            #acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "            precision = TP/(TP+FP) if (TP+FP) != 0 else 0\n",
    "            recall = TP/(TP+FN) if (TP+FN) != 0 else 0\n",
    "            F1_score = (2*precision*recall)/(precision+recall) if (precision+recall) != 0 else -1\n",
    "\n",
    "            if F1_score != -1:\n",
    "                if class_name == \"stepienie\": F1_score_stepienie_m  += F1_score\n",
    "                if class_name == \"wykruszenie\": F1_score_wykruszenie_m  += F1_score\n",
    "                if class_name == \"narost\": F1_score_narost_m  += F1_score\n",
    "                if class_name == \"zatarcie\": F1_score_zatarcie_m  += F1_score\n",
    "\n",
    "        if 2 in pred_classes: F1_score_global_stepienie.append(F1_score_stepienie_m) \n",
    "        if 1 in pred_classes: F1_score_global_narost.append(F1_score_narost_m)\n",
    "        if 3 in pred_classes: F1_score_global_zatarcie.append(F1_score_zatarcie_m) \n",
    "        if 0 in pred_classes: F1_score_global_wykruszenie.append(F1_score_wykruszenie_m)\n",
    "\n",
    "\n",
    "    F1_score_global = F1_score_global_wykruszenie + F1_score_global_zatarcie + F1_score_global_narost + F1_score_global_stepienie\n",
    "\n",
    "    if len(F1_score_global)==0: F1_score_global.append(-1)\n",
    "    if len(F1_score_global_wykruszenie)==0: F1_score_global_wykruszenie.append(-1)\n",
    "    if len(F1_score_global_zatarcie)==0: F1_score_global_zatarcie.append(-1)\n",
    "    if len(F1_score_global_narost)==0: F1_score_global_narost.append(-1)\n",
    "    if len(F1_score_global_stepienie)==0: F1_score_global_stepienie.append(-1)\n",
    "\n",
    "    print(statistics.mean(F1_score_global), statistics.mean(F1_score_global_stepienie), statistics.mean(F1_score_global_narost), statistics.mean(F1_score_global_zatarcie), statistics.mean(F1_score_global_wykruszenie))\n",
    "    return statistics.mean(F1_score_global), statistics.mean(F1_score_global_stepienie), statistics.mean(F1_score_global_narost), statistics.mean(F1_score_global_zatarcie), statistics.mean(F1_score_global_wykruszenie)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(segmentation_predictor,path_current_dataset):\n",
    "    pth = os.path.join(path_current_dataset, r'test').replace('\\\\\\\\','\\\\').replace('\\\\','/')\n",
    "\n",
    "    metrics_px = dict()\n",
    "    results = dict()\n",
    "    \n",
    "    for value in list(DICTIONARY_FAILURES.values())+[\"Global\"]:\n",
    "            results[value] = {\n",
    "                \"Recall\":0,\n",
    "                \"Precision\":0,\n",
    "                \"Accuracy\":0,\n",
    "                \"Specificity\":0,\n",
    "                \"F1\":0,\n",
    "            }\n",
    "    \n",
    "    for value in list(DICTIONARY_FAILURES.values())+[\"Global\"]:\n",
    "            metrics_px[value] = {\n",
    "                \"TP\":[],\n",
    "                \"TN\":[],\n",
    "                \"FP\":[],\n",
    "                \"FN\":[],\n",
    "            }\n",
    "    \n",
    "\n",
    "    for label in glob.glob(f'{pth}/*json'): # iterate through eval dataset\n",
    "        base_name = (label.replace('\\\\\\\\','\\\\').replace('\\\\','/').split('/')[-1]).split('.')[0]\n",
    "        file = open(label, 'r')\n",
    "        json_label = json.load(file )\n",
    "        im = cv.imread(os.path.join(pth,f\"{base_name}.png\"))\n",
    "        _, image_metrics = calculate_metrics_for_image(im, json_label, segmentation_predictor)\n",
    "        \n",
    "        for class_name in list(image_metrics.keys()):\n",
    "            for metric_name, metric_val in zip(list(image_metrics[class_name].keys()),list(image_metrics[class_name].values())):\n",
    "                metrics_px[class_name][metric_name].append(metric_val)\n",
    "                metrics_px[\"Global\"][metric_name].append(metric_val)\n",
    "\n",
    "    # calculate metrics for entire run\n",
    "    for class_name in list(results.keys()):\n",
    "        TP = sum(metrics_px[class_name][\"TP\"])\n",
    "        TN = sum(metrics_px[class_name][\"TN\"])\n",
    "        FP = sum(metrics_px[class_name][\"FP\"])\n",
    "        FN = sum(metrics_px[class_name][\"FN\"])\n",
    "        accuracy = (TP+TN)/(TP+TN+FP+FN) # Accuracy is a measure of how many of the predictions were correct\n",
    "        precision = TP/(TP+FP) if (TP+FP) != 0 else -1 # Precision is a measure of how many of the positive predictions made are correct (true positives)\n",
    "        recall = TP/(TP+FN) if (TP+FN) != 0 else -1 # Recall is a measure of how many of the positive cases the classifier correctly predicted\n",
    "        specificity = TN / (TN + FP) # Specificity is a measure of how many negative predictions made are correct (true negatives). \n",
    "        F1_score = (2*precision*recall) / (precision+recall) if (precision != -1 and recall != -1) else -1\n",
    "        results[class_name][\"Recall\"] = recall\n",
    "        results[class_name][\"Accuracy\"] = accuracy\n",
    "        results[class_name][\"Precision\"] = precision\n",
    "        results[class_name][\"Specificity\"] = specificity\n",
    "        results[class_name][\"F1\"] = F1_score\n",
    "\n",
    "   \n",
    "    for class_name in list(results.keys()):\n",
    "        print(\n",
    "            f\"\"\"\n",
    "            For class {class_name}\n",
    "                F1 = {results[class_name][\"F1\"]}\n",
    "            \"\"\"\n",
    "        )\n",
    "    return results\n",
    "\n",
    "def calculate_metrics_for_image(im, json_label, segmentation_predictor):\n",
    "        #cv.imshow(\"test\",im)\n",
    "        im_h, im_w, _ = im.shape\n",
    "\n",
    "        label_outputs = dict()\n",
    "        for value in DICTIONARY_FAILURES.values():\n",
    "            label_outputs[str(value)] = np.zeros((im.shape[0],im.shape[1],1),dtype=np.uint8)\n",
    "        \n",
    "        # Iterate over labels from .json file, merge it into 4 categories, draw it as bitmaps\n",
    "        for shape in json_label[\"shapes\"]:\n",
    "            point_list = np.array(shape['points'])\n",
    "            if len(point_list) > 2:\n",
    "                pts = point_list.reshape((-1, 1, 2))  \n",
    "                for class_name in DICTIONARY_FAILURES.values(): # Iterate over all instances classes\n",
    "                    if(shape[\"label\"]==class_name):\n",
    "                        label_outputs[class_name] = cv.fillPoly(label_outputs[class_name], np.int32([pts]), 255)\n",
    "                        \n",
    "        # Segmentation model inference\n",
    "        predictions = segmentation_predictor(im) # Make prediction \n",
    "        pred_masks = predictions[\"instances\"].to(\"cpu\").pred_masks.numpy()\n",
    "        pred_classes = predictions[\"instances\"].to(\"cpu\").pred_classes.numpy()\n",
    "        pred_masks = np.expand_dims(pred_masks, axis=3).astype(dtype=np.uint8) #[N H W Dummy]\n",
    "        \n",
    "        inference_outputs = dict() # Contains merged bitmaps for particular failures classes\n",
    "        pred_masks_instance = dict() # Contains temporary data used during merging\n",
    "        image_metrics_px = dict()\n",
    "        image_metrics_obj = dict()\n",
    "        for value in DICTIONARY_FAILURES.values():\n",
    "            inference_outputs[str(value)] = np.zeros((im.shape[0],im.shape[1],1),dtype=np.uint8)\n",
    "            pred_masks_instance[str(value)] = []\n",
    "            image_metrics_px[str(value)] = {\n",
    "                \"TP\":0.0,\n",
    "                \"TN\":0.0,\n",
    "                \"FP\":0.0,\n",
    "                \"FN\":0.0,\n",
    "            }\n",
    "            image_metrics_obj[str(value)] = {\n",
    "                \"TP\":0.0,\n",
    "                \"TN\":0.0,\n",
    "                \"FP\":0.0,\n",
    "                \"FN\":0.0,\n",
    "            }\n",
    "\n",
    "        # Iterate over predicted defects, search for duplicated instances of the same class and merge them into single bitmap.\n",
    "        for class_id, mask in zip(pred_classes,pred_masks): \n",
    "            for failure_id,failure_class in zip(DICTIONARY_FAILURES.keys(),DICTIONARY_FAILURES.values()): # Iterate over all instances classes\n",
    "                if(class_id == failure_id): \n",
    "                    pred_masks_instance[failure_class].append(mask) \n",
    "                    inference_outputs[failure_class] = cv.bitwise_or(src1=mask, src2=inference_outputs[failure_class])        \n",
    "        \n",
    "        for class_name in DICTIONARY_FAILURES.values():\n",
    "            # iterate through all potential failures\n",
    "        \n",
    "            # PIXEL METRICS\n",
    "\n",
    "            pred = inference_outputs[class_name]\n",
    "            label = label_outputs[class_name]\n",
    "            bitwiseOr = cv.bitwise_or(pred, label)\n",
    "            bitwiseAnd = cv.bitwise_and(pred, label) \n",
    "            #bitwiseXor = cv.bitwise_xor(pred, label)\n",
    "\n",
    "            TP = bitwiseAnd  # TP - a sample is predicted to be positive and its label is actually positive\n",
    "            TN = cv.bitwise_not(bitwiseOr) # TN - a sample is predicted to be negative and its label is actually negative\n",
    "            FP = cv.bitwise_xor(TP,pred) # FP - a sample is predicted to be positive and its label is actually negative\n",
    "            FN = cv.bitwise_and(cv.bitwise_not(pred),cv.bitwise_xor(label,TP)) # FN - a sample is predicted to be negative and its label is actually positive\n",
    "\n",
    "            im_size = im_h*im_w\n",
    "\n",
    "            TP = cv.countNonZero(TP) / im_size # normalize to image size\n",
    "            TN = cv.countNonZero(TN) / im_size\n",
    "            FP = cv.countNonZero(FP) / im_size\n",
    "            FN = cv.countNonZero(FN) / im_size\n",
    "\n",
    "            image_metrics_px[class_name][\"TP\"] = cv.countNonZero(TP)\n",
    "            image_metrics_px[class_name][\"TN\"] = cv.countNonZero(TN)\n",
    "            image_metrics_px[class_name][\"FP\"] = cv.countNonZero(FP)\n",
    "            image_metrics_px[class_name][\"FN\"] = cv.countNonZero(FN)\n",
    "\n",
    "        return pred_classes, image_metrics_px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/23 14:04:30 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
      "| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |\n",
      "|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
      "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
      "| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
      "| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
      "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
      "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
      "| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
      "| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
      "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
      "| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
      "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.10.conv1.*              | backbone.bottom_up.res4.10.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.10.conv2.*              | backbone.bottom_up.res4.10.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.10.conv3.*              | backbone.bottom_up.res4.10.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.11.conv1.*              | backbone.bottom_up.res4.11.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.11.conv2.*              | backbone.bottom_up.res4.11.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.11.conv3.*              | backbone.bottom_up.res4.11.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.12.conv1.*              | backbone.bottom_up.res4.12.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.12.conv2.*              | backbone.bottom_up.res4.12.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.12.conv3.*              | backbone.bottom_up.res4.12.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.13.conv1.*              | backbone.bottom_up.res4.13.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.13.conv2.*              | backbone.bottom_up.res4.13.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.13.conv3.*              | backbone.bottom_up.res4.13.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.14.conv1.*              | backbone.bottom_up.res4.14.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.14.conv2.*              | backbone.bottom_up.res4.14.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.14.conv3.*              | backbone.bottom_up.res4.14.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.15.conv1.*              | backbone.bottom_up.res4.15.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.15.conv2.*              | backbone.bottom_up.res4.15.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.15.conv3.*              | backbone.bottom_up.res4.15.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.16.conv1.*              | backbone.bottom_up.res4.16.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.16.conv2.*              | backbone.bottom_up.res4.16.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.16.conv3.*              | backbone.bottom_up.res4.16.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.17.conv1.*              | backbone.bottom_up.res4.17.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.17.conv2.*              | backbone.bottom_up.res4.17.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.17.conv3.*              | backbone.bottom_up.res4.17.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.18.conv1.*              | backbone.bottom_up.res4.18.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.18.conv2.*              | backbone.bottom_up.res4.18.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.18.conv3.*              | backbone.bottom_up.res4.18.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.19.conv1.*              | backbone.bottom_up.res4.19.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.19.conv2.*              | backbone.bottom_up.res4.19.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.19.conv3.*              | backbone.bottom_up.res4.19.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.20.conv1.*              | backbone.bottom_up.res4.20.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.20.conv2.*              | backbone.bottom_up.res4.20.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.20.conv3.*              | backbone.bottom_up.res4.20.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.21.conv1.*              | backbone.bottom_up.res4.21.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.21.conv2.*              | backbone.bottom_up.res4.21.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.21.conv3.*              | backbone.bottom_up.res4.21.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.22.conv1.*              | backbone.bottom_up.res4.22.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.22.conv2.*              | backbone.bottom_up.res4.22.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.22.conv3.*              | backbone.bottom_up.res4.22.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.6.conv1.*               | backbone.bottom_up.res4.6.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.6.conv2.*               | backbone.bottom_up.res4.6.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.6.conv3.*               | backbone.bottom_up.res4.6.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.7.conv1.*               | backbone.bottom_up.res4.7.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.7.conv2.*               | backbone.bottom_up.res4.7.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.7.conv3.*               | backbone.bottom_up.res4.7.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.8.conv1.*               | backbone.bottom_up.res4.8.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.8.conv2.*               | backbone.bottom_up.res4.8.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.8.conv3.*               | backbone.bottom_up.res4.8.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res4.9.conv1.*               | backbone.bottom_up.res4.9.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
      "| backbone.bottom_up.res4.9.conv2.*               | backbone.bottom_up.res4.9.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
      "| backbone.bottom_up.res4.9.conv3.*               | backbone.bottom_up.res4.9.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
      "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
      "| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
      "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
      "| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
      "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
      "| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
      "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
      "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
      "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
      "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
      "| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
      "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |\n",
      "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |\n",
      "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |\n",
      "| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |\n",
      "| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |\n",
      "| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (16,) (16,1024)                                 |\n",
      "| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (5,) (5,1024)                                   |\n",
      "| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                             | (256,) (256,256,2,2)                            |\n",
      "| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
      "| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
      "| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
      "| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
      "| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                          | (4,) (4,256,1,1)                                |\n",
      "Treshold 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KacperMarciniak\\anaconda3\\envs\\env_main\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            For class wykruszenie\n",
      "                F1 = 0.4444444444444444\n",
      "            \n",
      "\n",
      "            For class narost\n",
      "                F1 = 0.4318181818181818\n",
      "            \n",
      "\n",
      "            For class stepienie\n",
      "                F1 = 0.4894736842105263\n",
      "            \n",
      "\n",
      "            For class zatarcie\n",
      "                F1 = 0.4390243902439025\n",
      "            \n",
      "\n",
      "            For class Global\n",
      "                F1 = 0.46544428772919605\n",
      "            \n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_000_129.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_021_141.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_028_117.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_035_049.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_042_024.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_049_147.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_056_043.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_056_080.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_063_012.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_063_018.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_063_086.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_063_092.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_063_117.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_063_123.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_063_135.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_070_000.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_070_172.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_070_178.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_077_006.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_112_018.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_126_141.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_133_012.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_133_061.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_133_080.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_133_098.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_133_141.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_140_098.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_196_055.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_196_080.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_196_086.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_196_123.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_196_184.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_203_030.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_203_036.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_203_117.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_203_141.png\n",
      "Z:/TCM/trening/DATASETY/segmentacja/DAT_3_v2/test\\20210621_092043_203_166.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1468\\3384572918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0meval_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCURRENT_DATASET\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# OLD EVAL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0meval_results_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_eval_old\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCURRENT_DATASET\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mF1_scores_global_old\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_results_old\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mF1_scores_stepienie_old\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_results_old\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1468\\1491714847.py\u001b[0m in \u001b[0;36mcustom_eval_old\u001b[1;34m(segmentation_predictor, path_current_dataset)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mjson_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mf\"{base_name}.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mf\"{base_name}.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "F1_scores = []\n",
    "F1_scores_stepienie, F1_scores_wykruszenie, F1_scores_zatarcie, F1_scores_narost = [],[],[],[]\n",
    "Accuracy, Specificity = [],[]\n",
    "tresholds = []\n",
    "\n",
    "output_metrics = dict()\n",
    "for value in list(DICTIONARY_FAILURES.values())+[\"Global\"]:\n",
    "    output_metrics[value] = {\n",
    "            \"Recall\":[],\n",
    "            \"Precision\":[],\n",
    "            \"Accuracy\":[],\n",
    "            \"Specificity\":[],\n",
    "            \"F1\":[],\n",
    "        }\n",
    "\n",
    "if USE_OLD_EVAL:\n",
    "    F1_scores_global_old = list()\n",
    "    F1_scores_stepienie_old = list()\n",
    "    F1_scores_narost_old =  list()\n",
    "    F1_scores_zatarcie_old =  list()\n",
    "    F1_scores_wykruszenie_old =  list()\n",
    "\n",
    "for TRESHOLD in np.arange(0.3, 1.0, 0.05): #Iterate over various tresholds to find best results\n",
    "    TRESHOLD = float(round(TRESHOLD,2))\n",
    "    tresholds.append(TRESHOLD*100)\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = TRESHOLD\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    test_metadata = MetadataCatalog.get(\"TCM_test\")\n",
    "    print(\"Treshold\",TRESHOLD)\n",
    "    # NEW EVAL\n",
    "    eval_results = custom_eval(predictor, CURRENT_DATASET)\n",
    "    # OLD EVAL\n",
    "    if USE_OLD_EVAL:\n",
    "        eval_results_old = custom_eval_old(predictor, CURRENT_DATASET)\n",
    "        F1_scores_global_old.append(eval_results_old[0])\n",
    "        F1_scores_stepienie_old.append(eval_results_old[1])\n",
    "        F1_scores_narost_old.append(eval_results_old[2])\n",
    "        F1_scores_zatarcie_old.append(eval_results_old[3])\n",
    "        F1_scores_wykruszenie_old.append(eval_results_old[4])\n",
    "\n",
    "    for class_name in list(eval_results.keys()):\n",
    "        for metric in list(eval_results[class_name].keys()):\n",
    "            output_metrics[class_name][metric].append(eval_results[class_name][metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = PATH_TRAINING_OUTPUT_DIR_SEGMENTATION\n",
    "\n",
    "fig_class_scores, axes = plt.subplots(nrows=2,ncols=2)\n",
    "axes = axes.flatten()\n",
    "\n",
    "fig_class_scores.suptitle(\"Metrics (Classes)\")\n",
    "class_titles = list(DICTIONARY_FAILURES.values())\n",
    "for i,ax in enumerate(axes):\n",
    "    current_class_data = output_metrics[class_titles[i]]\n",
    "    ax.set_xlabel('Treshold [%]')\n",
    "    ax.set_ylabel('Metric')\n",
    "    ax.set_title(class_titles[i])\n",
    "    ax.grid(alpha=0.5)\n",
    "    for key,data in zip(list(current_class_data.keys()),list(current_class_data.values())):\n",
    "        ax.plot(tresholds,data,marker=\"o\",linestyle=\"none\",label=key)\n",
    "    ax.legend()\n",
    "fig_class_scores.set_size_inches(10,10)\n",
    "fig_class_scores.tight_layout()\n",
    "fig_class_scores.savefig(os.path.join(experiment_folder,'F1_class_scores.png'))\n",
    "fig_class_scores.show()\n",
    "\n",
    "fig_global_metrics, axes = plt.subplots(ncols=5)\n",
    "axes = axes.flatten()\n",
    "\n",
    "fig_global_metrics.suptitle(\"Metrics (Global)\")\n",
    "for i,ax in enumerate(axes):\n",
    "    metric_key,metric_val = list(output_metrics[\"Global\"].keys())[i], list(output_metrics[\"Global\"].values())[i]\n",
    "    ax.plot(tresholds,metric_val,marker=\"o\",linestyle=\"none\",label=metric_key)\n",
    "    ax.set_xlabel('Treshold [%]')\n",
    "    ax.set_ylabel('Metric')\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.set_title(metric_key)\n",
    "fig_global_metrics.set_size_inches(16,6)\n",
    "fig_global_metrics.tight_layout()\n",
    "fig_global_metrics.savefig(os.path.join(experiment_folder,'Global_metrics.png'))\n",
    "fig_global_metrics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_OLD_EVAL:\n",
    "    global_F1_max_old = max(F1_scores_global_old)\n",
    "\n",
    "    params = {\n",
    "        \"F1\": global_F1_max_old,\n",
    "        \"tresh\": tresholds[F1_scores_global_old.index(global_F1_max_old)],\n",
    "        \"F1_stepienie\": F1_scores_stepienie_old[F1_scores_global_old.index(global_F1_max_old)],\n",
    "        \"F1_narost\": F1_scores_narost_old[F1_scores_global_old.index(global_F1_max_old)],\n",
    "        \"F1_zatarcie\": F1_scores_zatarcie_old[F1_scores_global_old.index(global_F1_max_old)],\n",
    "        \"F1_wykruszenie\": F1_scores_wykruszenie_old[F1_scores_global_old.index(global_F1_max_old)],\n",
    "    }\n",
    "\n",
    "    print(\"OLD PARAMETERS\")\n",
    "    print(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('env_main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58c64561d3c79ee31cfc9210dc9ae71e62823c70a9c0b76afd259aeabe3e4d26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
